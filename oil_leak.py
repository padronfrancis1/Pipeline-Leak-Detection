# -*- coding: utf-8 -*-
"""oil_leak.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13sDEf2901n0g7JQ35uXZ7KAnPQqIGAKz

# Load dataset
"""

import numpy as np
import pandas as pd

data = pd.read_csv('data.csv')
data.info()
print(data.head())
print(data.describe())

# Removing outliers
def RemoveOutliers(df, cols):
    for col in cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
    return df

"""# Data cleaning and Exploratory Data Analysis (EDA)
Data is imbalanced on Condition column - will be addressed later on model training using SMOTE
"""

data.isnull().sum()

# Unique values on categorical columns
print(data['Medium'].value_counts())
print(data['Condition'].value_counts())

from sklearn.cluster import KMeans
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
sns.histplot(data['Condition'], bins=20)
plt.title('Distribution of Condition')
plt.xlabel('Condition')
plt.ylabel('Frequency')
plt.show()

# import seaborn as sns
# import matplotlib.pyplot as plt

# sns.pairplot(data, hue='Condition', palette='Set1')
# plt.suptitle('Pairplot of Features by Condition', fontsize=16)

# plt.show()

"""# Correlation - All columns exhibit a high degree of correlation with one another.
# So which column to use?
"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(14, 10))

sns.heatmap(
    data.drop(columns=['Medium', 'Condition']).corr(),
    annot=True,
    cmap='coolwarm',
    fmt=".2f",
    linewidths=0.5,
    annot_kws={"size": 10},
    cbar_kws={"shrink": 0.8}
)

plt.title('Correlation Matrix of Features', fontsize=16)
plt.xticks(rotation=45, fontsize=10, ha='right')  # Rotate x-axis labels
plt.yticks(rotation=0, fontsize=10)  # Rotate y-axis labels

plt.show()

# EDA - Feature Engineering - PCA
from sklearn.decomposition import PCA

# Determine how many n_components to use
pca = PCA().fit(X=data.drop(columns=['Medium', 'Condition']))
print(pca.explained_variance_ratio_)

feature_names = data.drop(columns=['Medium', 'Condition']).columns
components_df = pd.DataFrame(
    pca.components_,
    columns=feature_names,
    index=[f"PC{i+1}" for i in range(pca.n_components_)]
)
print("Top features contributing to PC1:")
print(components_df.loc['PC1'].abs().sort_values(ascending=False))
print("\nTop features contributing to PC2:")
print(components_df.loc['PC2'].abs().sort_values(ascending=False))

X_pca = PCA(n_components=2).fit_transform(X=data.drop(columns=['Medium', 'Condition']))
pca_columns = [f"PC{i+1}" for i in range(X_pca.shape[1])]
pca_df = pd.DataFrame(X_pca, columns=pca_columns)

# Hybrid Approach:
# Use PCA to identify important patterns.
# - Select the top contributing features from PCA for further analysis or modeling.
# - This balances dimensionality reduction, interpretability, and domain relevance.

plt.figure(figsize=(10, 6))
sns.scatterplot(data=data, x=data['P5: Centroid Frequency'], y=data['P6: Std Dev Centroid Frequency'], hue=data['Condition'])
plt.title('Scatter Plot of P5 vs. P6 by Condition')
plt.xlabel('P5: Centroid Frequency')
plt.ylabel('P6: Std Dev Centroid Frequency')
plt.legend(title='Condition')
plt.show()

# Still part of EDA
plt.figure(figsize=(10, 6))
sns.boxplot(x='Condition', y='P5: Centroid Frequency', data=data)
plt.title('Box Plot of P5: Centroid Frequency by Condition')
plt.xlabel('Condition')
plt.ylabel('P5: Centroid Frequency')
plt.show()

# Standardizing data (Scaling/Encoding)
import pandas as pd
from sklearn.preprocessing import StandardScaler, OrdinalEncoder
from sklearn.compose import ColumnTransformer

encoder = OrdinalEncoder(categories=[['Normal', 'Leak']])
data['Condition'] = encoder.fit_transform(data[['Condition']])
data['Condition'] = data['Condition'].astype(int)
data.head()

scaler = StandardScaler()
for columns in data.drop(columns=['Condition', 'Medium']).columns:
    data[columns] = scaler.fit_transform(data[[columns]])

data.head()

# Visuals on features to use after scaling
plt.figure(figsize=(10, 6))
sns.scatterplot(data=data, x=data['P5: Centroid Frequency'], y=data['P6: Std Dev Centroid Frequency'], hue=data['Condition'])
plt.title('Scatter Plot of P5 vs. P6 by Condition')
plt.xlabel('P5: Centroid Frequency')
plt.ylabel('P6: Std Dev Centroid Frequency')
plt.legend(title='Condition')
plt.show()

data = RemoveOutliers(data, ['P5: Centroid Frequency', 'P6: Std Dev Centroid Frequency'])
print(data['Condition'].value_counts())

# Visualize the cleaned data
plt.figure(figsize=(10, 6))
sns.scatterplot(data=data, x='P5: Centroid Frequency',
                y='P6: Std Dev Centroid Frequency',
                hue='Condition')
plt.title('Scatter Plot of P5 vs. P6 by Condition')
plt.xlabel('P5: Centroid Frequency')
plt.ylabel('P6: Std Dev Centroid Frequency')
plt.legend(title='Condition')
plt.grid()
plt.show()

"""# Modeling"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score

data.drop(columns=['Medium'], inplace=True)
selected_columns = ['P5: Centroid Frequency', 'P6: Std Dev Centroid Frequency', 'Condition']
modeling_data = data.drop(columns=[c for c in data.columns if c not in selected_columns])
print(modeling_data.head())
X = modeling_data.drop(columns=['Condition'])
y = modeling_data['Condition']

# Regular split and single model use
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
# Evaluation
y_pred = rf.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# Using kFolds
kf = KFold(n_splits=5, shuffle=True, random_state=42)
for train_idx, test_idx in kf.split(X):
  X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
  y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

  rf.fit(X_train, y_train)
  y_pred = rf.predict(X_test)
  mse = mean_squared_error(y_test, y_pred)
  r2 = r2_score(y_test, y_pred)
avg_r2 = cross_val_score(rf, X, y, cv=kf, scoring='r2').mean()
print(f"Average R-squared: {avg_r2}")

# Multiple models with cross-validation
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVR
from sklearn.metrics import confusion_matrix
models = {
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Logistic Regression": LogisticRegression(random_state=42),
    "Support Vector Machine": SVR(),
}

# foreach Condition (cluster)
  # foreach Model
    # foreach k-folds
      # train, predict, and evaluate
        # Take average

X_super = data.drop(columns=['Condition'])
y_super = data['Condition']
r2_scores = []
mse_scores = []
cm_scores = []

for model_name, model in models.items():
  print("--------------------------------")
  print(model_name)
  cm = None
  for train_idx, test_idx in kf.split(X_super):

    X_train, X_test = X_super.iloc[train_idx], X_super.iloc[test_idx]
    y_train, y_test = y_super.iloc[train_idx], y_super.iloc[test_idx]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test).astype(int)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    if cm is None:
      cm = confusion_matrix(y_test, y_pred)
    else:
      cm += confusion_matrix(y_test, y_pred)

    r2_scores.append(r2)
    mse_scores.append(mse)
    cm_scores.append(cm)

  avg_r2 = np.mean(r2_scores)
  avg_mse = np.mean(mse_scores)
  avg_cm = cm / kf.get_n_splits()
  print(f"Average R-squared: {np.mean(r2_scores)}")
  print(f"Average MSE: {np.mean(mse_scores)}")
  print(f"{avg_cm.astype(int)}")